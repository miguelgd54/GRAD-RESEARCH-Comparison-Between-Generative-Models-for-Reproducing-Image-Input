# Comparison Between Generative-Models for Reproducing Image Input

This project is for a graduate level class that compares various generative machine learning models for image reproduction. 
Most of these models are based on Convolutional Neural Networks and Recurrent Neural Networks. Datasets used are the MNIST and CelebA set.

Names of the classifiers tested in this project: Wasserstein Auto-Encoders, Deep Convolutional Generative Adversarial Networks, and Variational Autoencoder.
They're unsupervised machine learning algorithms.

The paper contains all the info and details about the project and all the tests/experiments run. Look at the .pdf file to take a look at the project's paper. The associated outputs are also included.
